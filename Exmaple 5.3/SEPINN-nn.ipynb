{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f89ad74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "import time\n",
    "from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker\n",
    "import math\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(12345)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(12345)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': print(torch.cuda.get_device_name()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c84154d",
   "metadata": {},
   "source": [
    "# Data Prep\n",
    "\n",
    "Training and Testing data is prepared from the solution file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94c9ce7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 32\n",
    "x_1 = np.linspace(-1, 1, 2*n+1)\n",
    "y_1 = np.linspace(1, 0, n+1)\n",
    "z_1 = np.linspace(1, -1, 2*n+1)\n",
    "Z_1, X_1, Y_1 = np.meshgrid(z_1, x_1, y_1)\n",
    "x_2 = np.linspace(-1, 0, n+1)\n",
    "y_2 = np.linspace(-1/n, -1, n)\n",
    "Z_2, X_2, Y_2 = np.meshgrid(z_1, x_2, y_2)\n",
    "\n",
    "x = np.vstack((X_1.flatten(order='F')[:, None], X_2.flatten(order='F')[:, None]))\n",
    "y = np.vstack((Y_1.flatten(order='F')[:, None], Y_2.flatten(order='F')[:, None]))\n",
    "z = np.vstack((Z_1.flatten(order='F')[:, None], Z_2.flatten(order='F')[:, None]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584d4f6e",
   "metadata": {},
   "source": [
    "# Test Data\n",
    "\n",
    "We prepare the test data to compare against the solution produced by the PINN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99560bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_16056/2403138763.py:12: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  PHI = 2 * np.arctan(-math.e**(-np.pi*r)*np.sin(np.pi*z)/(1+math.e**(-np.pi*r)*np.cos(np.pi*z)))\n"
     ]
    }
   ],
   "source": [
    "X_v_test = np.hstack((x, y, z))\n",
    "v_true = (x-x**3)*(y-y**3)*(1-z**2)\n",
    "r = np.sqrt(x**2 + y**2)\n",
    "theta = np.arctan2(y, x)\n",
    "theta = np.where(theta < 0, theta + 2*np.pi, theta)\n",
    "sd = r**(2/3) * np.sin(2*theta/3)\n",
    "R = 1/2\n",
    "etad = np.where(r < R, 15 / 16 * (\n",
    "                    8 / 15 - (4 * r / R - 3) + 2 / 3 * (4 * r / R - 3) ** 3 - 1 / 5 * (4 * r / R - 3) ** 5), 0)\n",
    "etad = np.where(r < R/2, 1, etad)\n",
    "\n",
    "PHI = 2 * np.arctan(-math.e**(-np.pi*r)*np.sin(np.pi*z)/(1+math.e**(-np.pi*r)*np.cos(np.pi*z)))\n",
    "u_true = v_true + sd * etad * PHI\n",
    "\n",
    "lb = np.array([-1, -1, -1]) #lower bound\n",
    "ub = np.array([1, 1, 1])  #upper bound"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d05d479",
   "metadata": {},
   "source": [
    "# Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7a92c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingdata(N_v,N_f):\n",
    "    \n",
    "    x_1 = np.linspace(-1,1,2*n+1)\n",
    "    x_3 = np.linspace((n-1)/n,-(n-1)/n,2*n-1)\n",
    "    X, Z = np.meshgrid(x_1,x_3)\n",
    "    edge1_x = np.hstack((X.flatten('F')[:,None], np.linspace(1,1,(2*n+1)*(2*n-1))[:,None], Z.flatten('F')[:,None]))\n",
    "    edge1_v = np.linspace(0,0,(2*n+1)*(2*n-1))[:,None]\n",
    "    \n",
    "    x_3 = np.linspace((n-1)/n,-(n-1)/n,2*n-1)\n",
    "    x_2 = np.linspace(0,(n-1)/n,n)\n",
    "    Y, Z = np.meshgrid(x_2,x_3)\n",
    "    edge2_x = np.hstack((np.linspace(1,1,n*(2*n-1))[:,None], Y.flatten('F')[:,None], Z.flatten('F')[:,None]))\n",
    "    edge2_v = np.linspace(0,0,n*(2*n+1))[:,None]\n",
    "    \n",
    "    x_3 = np.linspace((n-1)/n,-(n-1)/n,2*n-1)\n",
    "    x_1 = np.linspace(0,(n-1)/n,n)\n",
    "    X, Z = np.meshgrid(x_1,x_3)\n",
    "    edge3_x = np.hstack((X.flatten('F')[:,None], np.linspace(0,0,n*(2*n-1))[:,None], Z.flatten('F')[:,None]))\n",
    "    edge3_v = np.linspace(0,0,n*(2*n-1))[:,None]\n",
    "    \n",
    "    x_3 = np.linspace((n-1)/n,-(n-1)/n,2*n-1)\n",
    "    x_2 = np.linspace(-1,-1/n,n)\n",
    "    Y, Z = np.meshgrid(x_2,x_3)\n",
    "    edge4_x = np.hstack((np.linspace(0,0,n*(2*n-1))[:,None], Y.flatten('F')[:,None], Z.flatten('F')[:,None]))\n",
    "    edge4_v = np.linspace(0,0,n*(2*n-1))[:,None]\n",
    "    \n",
    "    x_3 = np.linspace((n-1)/n,-(n-1)/n,2*n-1)\n",
    "    x_1 = np.linspace(-1,-1/n,n)\n",
    "    X, Z = np.meshgrid(x_1,x_3)\n",
    "    edge5_x = np.hstack((X.flatten('F')[:,None], np.linspace(-1,-1,n*(2*n-1))[:,None], Z.flatten('F')[:,None]))\n",
    "    edge5_v = np.linspace(0,0,n*(2*n-1))[:,None]\n",
    "    \n",
    "    x_3 = np.linspace((n-1)/n,-(n-1)/n,2*n-1)\n",
    "    x_2 = np.linspace(-(n-1)/n,(n-1)/n,2*n-1)\n",
    "    Y, Z = np.meshgrid(x_2,x_3)\n",
    "    edge6_x = np.hstack((np.linspace(-1,-1,(2*n-1)**2)[:,None], Y.flatten('F')[:,None], Z.flatten('F')[:,None]))\n",
    "    edge6_v = np.linspace(0,0,(2*n-1)**2)[:,None]\n",
    "    \n",
    "    x_1 = np.linspace(-1, 1, 2*n+1)\n",
    "    y_1 = np.linspace(1, 0, n+1)\n",
    "    Y_1, X_1 = np.meshgrid(y_1, x_1)\n",
    "    x_2 = np.linspace(-1, 0, n+1)\n",
    "    y_2 = np.linspace(-1/n, -1, n)\n",
    "    Y_2, X_2 = np.meshgrid(y_2, x_2)\n",
    "    x = np.vstack((X_1.flatten(order='F')[:, None], X_2.flatten(order='F')[:, None]))\n",
    "    y = np.vstack((Y_1.flatten(order='F')[:, None], Y_2.flatten(order='F')[:, None]))\n",
    "    \n",
    "    edge7_x = np.hstack((x, y, np.linspace(-1,-1,(3*n+1)*(n+1))[:,None]))\n",
    "    edge7_v = np.linspace(0,0,(3*n+1)*(n+1))[:,None]\n",
    "    edge8_x = np.hstack((x, y, np.linspace(1,1,(3*n+1)*(n+1))[:,None]))\n",
    "    edge8_v = edge7_v\n",
    "    \n",
    "    all_X_v_train = np.vstack([edge1_x, edge2_x, edge3_x, edge4_x, edge5_x, edge6_x, edge7_x, edge8_x])\n",
    "    all_v_train = np.vstack([edge1_v, edge2_v, edge3_v, edge4_v, edge5_v, edge6_v, edge7_v, edge8_v])\n",
    "\n",
    "    # choose random N_v points for training\n",
    "    all_X_v_train_r = np.sqrt(all_X_v_train[:, 0]**2 + all_X_v_train[:, 1]**2)\n",
    "    probability = np.where(all_X_v_train_r == 0, 0, 1)\n",
    "    probability = probability / np.sum(probability)\n",
    "    idx = np.random.choice(all_X_v_train.shape[0], N_v, replace=False, p=probability)\n",
    "    X_v_train = all_X_v_train[idx[0:N_v], :]  # choose indices from  set 'idx' (x,t)\n",
    "    v_train = all_v_train[idx[0:N_v], :]\n",
    "    \n",
    "    '''Collocation Points'''\n",
    "\n",
    "    # N_f sets of tuples(x,t)\n",
    "#     probability = np.where(r == 0, 0, 1)\n",
    "#     probability = probability / np.sum(probability)\n",
    "#     idx = np.random.choice(X_v_test.shape[0], N_f, replace=False, p=probability.T[0])\n",
    "#     X_f = X_v_test[idx[0:N_f], :]\n",
    "\n",
    "    prob = np.where(np.random.rand(1, N_f) < 2/3, 1, 0)\n",
    "    N = np.sum(prob)\n",
    "    print(N)\n",
    "    \n",
    "    lb = np.array([-1, -1, -1])\n",
    "    ub = np.array([0, 1, 1])\n",
    "    X_f_1 = lb + (ub - lb) * lhs(3, N)\n",
    "    lb = np.array([0, 0, -1])\n",
    "    ub = np.array([1, 1, 1])\n",
    "    X_f_2 = lb + (ub - lb) * lhs(3, N_f - N)\n",
    "    X_f = np.vstack((X_f_1, X_f_2))\n",
    "\n",
    "    X_f_train = np.vstack((X_f, X_v_train))  # append training points to collocation points\n",
    "\n",
    "    return X_f_train, X_v_train, v_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edf6b7f",
   "metadata": {},
   "source": [
    "# PINN\n",
    "\n",
    "Creating sequential layers using the class\n",
    "tf.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f82fa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers,layers0):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "        'activation function'\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "        'loss function'\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "    \n",
    "        'Initialise neural network as a nn.MSELosslist using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        self.linears0 = nn.ModuleList([nn.Linear(layers0[i], layers0[i+1]) for i in range(len(layers0)-1)])\n",
    "        \n",
    "        'Xavier Normal Initialization'\n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        for i in range(len(layers)-1):\n",
    "            \n",
    "            # weights from a normal distribution with \n",
    "            # Recommended gain value for tanh = 5/3?\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            \n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data)\n",
    "            \n",
    "        for i in range(len(layers0)-1):\n",
    "            \n",
    "            # weights from a normal distribution with \n",
    "            # Recommended gain value for tanh = 5/3?\n",
    "            nn.init.xavier_normal_(self.linears0[i].weight.data, gain=1.0)\n",
    "            \n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears0[i].bias.data)\n",
    "            \n",
    "    def forward(self,x):\n",
    "        \n",
    "        if torch.is_tensor(x) != True:         \n",
    "            x = torch.from_numpy(x)                \n",
    "        \n",
    "        u_b = torch.from_numpy(ub).float().to(device)\n",
    "        l_b = torch.from_numpy(lb).float().to(device)\n",
    "                      \n",
    "        #preprocessing input \n",
    "        x = (x - l_b)/(u_b - l_b) #feature scaling\n",
    "        \n",
    "        #convert to float\n",
    "        a = x.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            \n",
    "            z = self.linears[i](a)\n",
    "                        \n",
    "            a = self.activation(z)\n",
    "            \n",
    "        a = self.linears[-1](a)\n",
    "        \n",
    "        return a\n",
    "    \n",
    "    def forward0(self,x):\n",
    "        \n",
    "        if torch.is_tensor(x) != True:         \n",
    "            x = torch.from_numpy(x)                \n",
    "\n",
    "        u_b = torch.from_numpy(ub).float().to(device)\n",
    "        l_b = torch.from_numpy(lb).float().to(device)\n",
    "                      \n",
    "        #preprocessing input \n",
    "        x = (x - l_b)/(u_b - l_b) #feature scaling\n",
    "        \n",
    "        #convert to float\n",
    "        a = x.float()\n",
    "        \n",
    "        for i in range(len(layers0)-2):\n",
    "            \n",
    "            z = self.linears0[i](a)\n",
    "                        \n",
    "            a = self.activation(z)\n",
    "            \n",
    "        a = self.linears0[-1](a)\n",
    "        \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC(self,x,y):\n",
    "        \n",
    "        x_1_f = x[:,[0]]\n",
    "        x_2_f = x[:,[1]]\n",
    "        x_3_f = x[:,[2]]\n",
    "        r = torch.sqrt(x_1_f ** 2 + x_2_f ** 2)\n",
    "        theta = np.arctan2(x_2_f, x_1_f)\n",
    "        theta = torch.where(theta < 0, theta + 2 * np.pi, theta)\n",
    "        s = r**(2/3) * np.sin(2*theta/3)\n",
    "        eta = torch.where(r < R, 15 / 16 * (8 / 15 - (8 * r - 3) + 2 / 3 * (8 * r - 3) ** 3 - 1 / 5 * (8 * r - 3) ** 5), 0)\n",
    "        eta = torch.where(r < R/2, 1, eta)\n",
    "        p = s * eta\n",
    "        \n",
    "        g = x.clone()\n",
    "        \n",
    "        g.requires_grad = True\n",
    "        \n",
    "        PHI = self.forward0(g)\n",
    "        \n",
    "        loss_v = self.loss_function(self.forward(g), - p * PHI)\n",
    "        #loss_v = self.loss_function(self.forward(g), y)\n",
    "                \n",
    "        return loss_v\n",
    "    \n",
    "    def loss_PDE(self, x_to_train_f):\n",
    "                \n",
    "        x_1_f = x_to_train_f[:,[0]]\n",
    "        x_2_f = x_to_train_f[:,[1]]\n",
    "        x_3_f = x_to_train_f[:,[2]]\n",
    "                        \n",
    "        g = x_to_train_f.clone()\n",
    "                        \n",
    "        g.requires_grad = True\n",
    "        \n",
    "        vv = self.forward(g)\n",
    "                \n",
    "        v_x = autograd.grad(vv,g,torch.ones([x_to_train_f.shape[0], 1]).to(device), retain_graph=True, create_graph=True)[0]        \n",
    "        v_xx = autograd.grad(v_x[:,[0]],g,torch.ones([x_to_train_f.shape[0], 1]).to(device), retain_graph=True, create_graph=True)[0]\n",
    "        v_yy = autograd.grad(v_x[:,[1]],g,torch.ones([x_to_train_f.shape[0], 1]).to(device), retain_graph=True, create_graph=True)[0]\n",
    "        v_zz = autograd.grad(v_x[:,[2]],g,torch.ones([x_to_train_f.shape[0], 1]).to(device), retain_graph=True, create_graph=True)[0]\n",
    "        \n",
    "        v_xx_1 = v_xx[:,[0]]\n",
    "        v_xx_2 = v_yy[:,[1]]\n",
    "        v_xx_3 = v_zz[:,[2]]\n",
    "                        \n",
    "        r = torch.sqrt(x_1_f ** 2 + x_2_f ** 2)\n",
    "        theta = np.arctan2(x_2_f, x_1_f)\n",
    "        theta = torch.where(theta < 0, theta + 2 * np.pi, theta)\n",
    "        z = x_3_f\n",
    "        \n",
    "        deltap = torch.where(r < R, (2*r**(2/3)*np.sin((2*theta)/3)*((2*np.pi**2*math.e**(-3*np.pi*r)*np.sin(np.pi*z)**3)/(math.e**(-r*np.pi)*np.cos(z*np.pi) + 1)**3 - (np.pi**2*math.e**(-np.pi*r)*np.sin(np.pi*z))/(math.e**(-np.pi*r)*np.cos(np.pi*z) + 1) + (3*np.pi**2*math.e**(-2*np.pi*r)*np.cos(np.pi*z)*np.sin(np.pi*z))/(math.e**(-r*np.pi)*np.cos(z*np.pi) + 1)**2)*((15*r)/2 - (5*(8*r - 3)**3)/8 + (3*(8*r - 3)**5)/16 - 53/16))/((math.e**(-2*np.pi*r)*np.sin(np.pi*z)**2)/(math.e**(-r*np.pi)*np.cos(z*np.pi) + 1)**2 + 1) - (8*np.arctan((math.e**(-np.pi*r)*np.sin(np.pi*z))/(math.e**(-np.pi*r)*np.cos(np.pi*z) + 1))*np.sin((2*theta)/3)*((15*r)/2 - (5*(8*r - 3)**3)/8 + (3*(8*r - 3)**5)/16 - 53/16))/(9*r**(4/3)) - (r*((4*np.arctan((math.e**(-np.pi*r)*np.sin(np.pi*z))/(math.e**(-np.pi*r)*np.cos(np.pi*z) + 1))*np.sin((2*theta)/3)*((15*r)/2 - (5*(8*r - 3)**3)/8 + (3*(8*r - 3)**5)/16 - 53/16))/(9*r**(4/3)) - 2*r**(2/3)*np.arctan((math.e**(-np.pi*r)*np.sin(np.pi*z))/(math.e**(-np.pi*r)*np.cos(np.pi*z) + 1))*np.sin((2*theta)/3)*(240*(8*r - 3)**3 - 1920*r + 720) - (8*np.arctan((math.e**(-np.pi*r)*np.sin(np.pi*z))/(math.e**(-np.pi*r)*np.cos(np.pi*z) + 1))*np.sin((2*theta)/3)*((15*(8*r - 3)**4)/2 - 15*(8*r - 3)**2 + 15/2))/(3*r**(1/3)) + (8*np.sin((2*theta)/3)*((np.pi*math.e**(-np.pi*r)*np.sin(np.pi*z))/(math.e**(-np.pi*r)*np.cos(np.pi*z) + 1) - (np.pi*math.e**(-2*np.pi*r)*np.cos(np.pi*z)*np.sin(np.pi*z))/(math.e**(-r*np.pi)*np.cos(z*np.pi) + 1)**2)*((15*r)/2 - (5*(8*r - 3)**3)/8 + (3*(8*r - 3)**5)/16 - 53/16))/(3*r**(1/3)*((math.e**(-2*np.pi*r)*np.sin(np.pi*z)**2)/(math.e**(-r*np.pi)*np.cos(z*np.pi) + 1)**2 + 1)) - (2*r**(2/3)*np.sin((2*theta)/3)*((np.pi**2*math.e**(-np.pi*r)*np.sin(np.pi*z))/(math.e**(-np.pi*r)*np.cos(np.pi*z) + 1) + (2*np.pi**2*math.e**(-3*np.pi*r)*np.cos(np.pi*z)**2*np.sin(np.pi*z))/(math.e**(-r*np.pi)*np.cos(z*np.pi) + 1)**3 - (3*np.pi**2*math.e**(-2*np.pi*r)*np.cos(np.pi*z)*np.sin(np.pi*z))/(math.e**(-r*np.pi)*np.cos(z*np.pi) + 1)**2)*((15*r)/2 - (5*(8*r - 3)**3)/8 + (3*(8*r - 3)**5)/16 - 53/16))/((math.e**(-2*np.pi*r)*np.sin(np.pi*z)**2)/(math.e**(-r*np.pi)*np.cos(z*np.pi) + 1)**2 + 1) + (4*r**(2/3)*np.sin((2*theta)/3)*((np.pi*math.e**(-np.pi*r)*np.sin(np.pi*z))/(math.e**(-np.pi*r)*np.cos(np.pi*z) + 1) - (np.pi*math.e**(-2*np.pi*r)*np.cos(np.pi*z)*np.sin(np.pi*z))/(math.e**(-r*np.pi)*np.cos(z*np.pi) + 1)**2)*((15*(8*r - 3)**4)/2 - 15*(8*r - 3)**2 + 15/2))/((math.e**(-2*np.pi*r)*np.sin(np.pi*z)**2)/(math.e**(-r*np.pi)*np.cos(z*np.pi) + 1)**2 + 1) + (2*r**(2/3)*np.sin((2*theta)/3)*((2*np.pi*math.e**(-2*np.pi*r)*np.sin(np.pi*z)**2)/(math.e**(-r*np.pi)*np.cos(z*np.pi) + 1)**2 - (2*np.pi*math.e**(-3*np.pi*r)*np.cos(np.pi*z)*np.sin(np.pi*z)**2)/(math.e**(-r*np.pi)*np.cos(z*np.pi) + 1)**3)*((np.pi*math.e**(-np.pi*r)*np.sin(np.pi*z))/(math.e**(-np.pi*r)*np.cos(np.pi*z) + 1) - (np.pi*math.e**(-2*np.pi*r)*np.cos(np.pi*z)*np.sin(np.pi*z))/(math.e**(-r*np.pi)*np.cos(z*np.pi) + 1)**2)*((15*r)/2 - (5*(8*r - 3)**3)/8 + (3*(8*r - 3)**5)/16 - 53/16))/((math.e**(-2*r*np.pi)*np.sin(z*np.pi)**2)/(math.e**(-np.pi*r)*np.cos(np.pi*z) + 1)**2 + 1)**2) - (4*np.arctan((math.e**(-np.pi*r)*np.sin(np.pi*z))/(math.e**(-np.pi*r)*np.cos(np.pi*z) + 1))*np.sin((2*theta)/3)*((15*r)/2 - (5*(8*r - 3)**3)/8 + (3*(8*r - 3)**5)/16 - 53/16))/(3*r**(1/3)) - 2*r**(2/3)*np.arctan((math.e**(-np.pi*r)*np.sin(np.pi*z))/(math.e**(-np.pi*r)*np.cos(np.pi*z) + 1))*np.sin((2*theta)/3)*((15*(8*r - 3)**4)/2 - 15*(8*r - 3)**2 + 15/2) + (2*r**(2/3)*np.sin((2*theta)/3)*((np.pi*math.e**(-np.pi*r)*np.sin(np.pi*z))/(math.e**(-np.pi*r)*np.cos(np.pi*z) + 1) - (np.pi*math.e**(-2*np.pi*r)*np.cos(np.pi*z)*np.sin(np.pi*z))/(math.e**(-r*np.pi)*np.cos(z*np.pi) + 1)**2)*((15*r)/2 - (5*(8*r - 3)**3)/8 + (3*(8*r - 3)**5)/16 - 53/16))/((math.e**(-2*np.pi*r)*np.sin(np.pi*z)**2)/(math.e**(-r*np.pi)*np.cos(z*np.pi) + 1)**2 + 1))/r - (2*r**(2/3)*np.sin((2*theta)/3)*((2*np.pi*math.e**(-3*np.pi*r)*np.sin(np.pi*z)**3)/(math.e**(-r*np.pi)*np.cos(z*np.pi) + 1)**3 + (2*np.pi*math.e**(-2*np.pi*r)*np.cos(np.pi*z)*np.sin(np.pi*z))/(math.e**(-r*np.pi)*np.cos(z*np.pi) + 1)**2)*((np.pi*math.e**(-2*np.pi*r)*np.sin(np.pi*z)**2)/(math.e**(-r*np.pi)*np.cos(z*np.pi) + 1)**2 + (np.pi*math.e**(-np.pi*r)*np.cos(np.pi*z))/(math.e**(-np.pi*r)*np.cos(np.pi*z) + 1))*((15*r)/2 - (5*(8*r - 3)**3)/8 + (3*(8*r - 3)**5)/16 - 53/16))/((math.e**(-2*r*np.pi)*np.sin(z*np.pi)**2)/(math.e**(-np.pi*r)*np.cos(np.pi*z) + 1)**2 + 1)**2, 0)\n",
    "        deltap = torch.where(r < R / 2, (r*((4*np.arctan((math.e**(-np.pi*r)*np.sin(np.pi*z))/(math.e**(-np.pi*r)*np.cos(np.pi*z) + 1))*np.sin((2*theta)/3))/(9*r**(4/3)) + (8*np.sin((2*theta)/3)*((np.pi*math.e**(-np.pi*r)*np.sin(np.pi*z))/(math.e**(-np.pi*r)*np.cos(np.pi*z) + 1) - (np.pi*math.e**(-2*np.pi*r)*np.cos(np.pi*z)*np.sin(np.pi*z))/(math.e**(-r*np.pi)*np.cos(z*np.pi) + 1)**2))/(3*r**(1/3)*((math.e**(-2*np.pi*r)*np.sin(np.pi*z)**2)/(math.e**(-r*np.pi)*np.cos(z*np.pi) + 1)**2 + 1)) - (2*r**(2/3)*np.sin((2*theta)/3)*((np.pi**2*math.e**(-np.pi*r)*np.sin(np.pi*z))/(math.e**(-np.pi*r)*np.cos(np.pi*z) + 1) + (2*np.pi**2*math.e**(-3*np.pi*r)*np.cos(np.pi*z)**2*np.sin(np.pi*z))/(math.e**(-r*np.pi)*np.cos(z*np.pi) + 1)**3 - (3*np.pi**2*math.e**(-2*np.pi*r)*np.cos(np.pi*z)*np.sin(np.pi*z))/(math.e**(-r*np.pi)*np.cos(z*np.pi) + 1)**2))/((math.e**(-2*np.pi*r)*np.sin(np.pi*z)**2)/(math.e**(-r*np.pi)*np.cos(z*np.pi) + 1)**2 + 1) + (2*r**(2/3)*np.sin((2*theta)/3)*((2*np.pi*math.e**(-2*np.pi*r)*np.sin(np.pi*z)**2)/(math.e**(-r*np.pi)*np.cos(z*np.pi) + 1)**2 - (2*np.pi*math.e**(-3*np.pi*r)*np.cos(np.pi*z)*np.sin(np.pi*z)**2)/(math.e**(-r*np.pi)*np.cos(z*np.pi) + 1)**3)*((np.pi*math.e**(-np.pi*r)*np.sin(np.pi*z))/(math.e**(-np.pi*r)*np.cos(np.pi*z) + 1) - (np.pi*math.e**(-2*np.pi*r)*np.cos(np.pi*z)*np.sin(np.pi*z))/(math.e**(-r*np.pi)*np.cos(z*np.pi) + 1)**2))/((math.e**(-2*r*np.pi)*np.sin(z*np.pi)**2)/(math.e**(-np.pi*r)*np.cos(np.pi*z) + 1)**2 + 1)**2) - (4*np.arctan((math.e**(-np.pi*r)*np.sin(np.pi*z))/(math.e**(-np.pi*r)*np.cos(np.pi*z) + 1))*np.sin((2*theta)/3))/(3*r**(1/3)) + (2*r**(2/3)*np.sin((2*theta)/3)*((np.pi*math.e**(-np.pi*r)*np.sin(np.pi*z))/(math.e**(-np.pi*r)*np.cos(np.pi*z) + 1) - (np.pi*math.e**(-2*np.pi*r)*np.cos(np.pi*z)*np.sin(np.pi*z))/(math.e**(-r*np.pi)*np.cos(z*np.pi) + 1)**2))/((math.e**(-2*np.pi*r)*np.sin(np.pi*z)**2)/(math.e**(-r*np.pi)*np.cos(z*np.pi) + 1)**2 + 1))/r + (8*np.arctan((math.e**(-np.pi*r)*np.sin(np.pi*z))/(math.e**(-np.pi*r)*np.cos(np.pi*z) + 1))*np.sin((2*theta)/3))/(9*r**(4/3)) - (2*r**(2/3)*np.sin((2*theta)/3)*((2*np.pi**2*math.e**(-3*np.pi*r)*np.sin(np.pi*z)**3)/(math.e**(-r*np.pi)*np.cos(z*np.pi) + 1)**3 - (np.pi**2*math.e**(-np.pi*r)*np.sin(np.pi*z))/(math.e**(-np.pi*r)*np.cos(np.pi*z) + 1) + (3*np.pi**2*math.e**(-2*np.pi*r)*np.cos(np.pi*z)*np.sin(np.pi*z))/(math.e**(-r*np.pi)*np.cos(z*np.pi) + 1)**2))/((math.e**(-2*np.pi*r)*np.sin(np.pi*z)**2)/(math.e**(-r*np.pi)*np.cos(z*np.pi) + 1)**2 + 1) + (2*r**(2/3)*np.sin((2*theta)/3)*((2*np.pi*math.e**(-3*np.pi*r)*np.sin(np.pi*z)**3)/(math.e**(-r*np.pi)*np.cos(z*np.pi) + 1)**3 + (2*np.pi*math.e**(-2*np.pi*r)*np.cos(np.pi*z)*np.sin(np.pi*z))/(math.e**(-r*np.pi)*np.cos(z*np.pi) + 1)**2)*((np.pi*math.e**(-2*np.pi*r)*np.sin(np.pi*z)**2)/(math.e**(-r*np.pi)*np.cos(z*np.pi) + 1)**2 + (np.pi*math.e**(-np.pi*r)*np.cos(np.pi*z))/(math.e**(-np.pi*r)*np.cos(np.pi*z) + 1)))/((math.e**(-2*r*np.pi)*np.sin(z*np.pi)**2)/(math.e**(-np.pi*r)*np.cos(np.pi*z) + 1)**2 + 1)**2, deltap)\n",
    "        \n",
    "        f = 6 * x_1_f * (x_2_f - x_2_f**3) * (1 - x_3_f**2) + 6 * x_2_f * (x_1_f - x_1_f**3) * (1 - x_3_f**2) + 2 * (x_2_f - x_2_f**3) * (x_1_f - x_1_f**3) - deltap\n",
    "        \n",
    "        s = r**(2/3) * np.sin(2*theta/3)\n",
    "        eta = torch.where(r < R, 15 / 16 * (8 / 15 - (8 * r - 3) + 2 / 3 * (8 * r - 3) ** 3 - 1 / 5 * (8 * r - 3) ** 5), 0)\n",
    "        eta = torch.where(r < R/2, 1, eta)\n",
    "        p = s * eta\n",
    "        \n",
    "        deltap0 = torch.where(r < R,\n",
    "                          -4 * (-7.5 * r - 0.1875 * (8 * r - 3) ** 5 + 0.625 * (8 * r - 3) ** 3 + 3.3125) * np.sin(\n",
    "                              2 * theta / 3) / (9 * r ** (4 / 3)) + (2 / 3 * (\n",
    "                                  -7.5 * r - 0.1875 * (8 * r - 3) ** 5 + 0.625 * (\n",
    "                                  8 * r - 3) ** 3 + 3.3125) * np.sin(2 * theta / 3) / r ** (1 / 3) + r ** (\n",
    "                                                                             2 / 3) * (\n",
    "                                                                             -7.5 * (8 * r - 3) ** 4 + 15.0 * (\n",
    "                                                                             8 * r - 3) ** 2 - 7.5) * np.sin(\n",
    "                              2 * theta / 3) + r * (-2 / 9 * (-7.5 * r - 0.1875 * (8 * r - 3) ** 5 + 0.625 * (\n",
    "                                  8 * r - 3) ** 3 + 3.3125) * np.sin(2 * theta / 3) / r ** (4 / 3) + 4 / 3 * (\n",
    "                                                            -7.5 * (8 * r - 3) ** 4 + 15.0 * (\n",
    "                                                            8 * r - 3) ** 2 - 7.5) * np.sin(\n",
    "                              2 * theta / 3) / r ** (1 / 3) + r ** (2 / 3) * (\n",
    "                                                            1920.0 * r - 240.0 * (8 * r - 3) ** 3 - 720.0) * np.sin(\n",
    "                              2 * theta / 3))) / r, 0)\n",
    "        deltap0 = torch.where(r < R / 2, 0, deltap0)\n",
    "        \n",
    "        p_r = torch.where(r < R, 0.625*(-8*r - 0.2*(8*r - 3)**5 + 0.666666666666667*(8*r - 3)**3 + 3.53333333333333)*np.sin(2*theta/3)/r**0.333333333333333 + 15*r**0.666666666666667*(-8.0*(8*r - 3)**4 + 16.0*(8*r - 3)**2 - 8)*np.sin(2*theta/3)/16, 0)\n",
    "        p_r = torch.where(r < R / 2, 0.666666666666667*np.sin(2*theta/3)/r**0.333333333333333, p_r)\n",
    "        p_theta = 2/3* eta * r**(2/3) * np.cos(2*theta/3)\n",
    "        \n",
    "        PHI = self.forward0(g)\n",
    "        PHI_x = autograd.grad(PHI,g,torch.ones([x_to_train_f.shape[0], 1]).to(device), retain_graph=True, create_graph=True)[0]        \n",
    "        \n",
    "        PHI_x_1 = PHI_x[:,[0]]\n",
    "        PHI_x_2 = PHI_x[:,[1]]\n",
    "        PHI_x_3 = PHI_x[:,[2]]\n",
    "        \n",
    "        PHI_xx = autograd.grad(PHI_x_1,g,torch.ones([x_to_train_f.shape[0], 1]).to(device), retain_graph=True, create_graph=True)[0]\n",
    "        PHI_yy = autograd.grad(PHI_x_2,g,torch.ones([x_to_train_f.shape[0], 1]).to(device), retain_graph=True, create_graph=True)[0]\n",
    "        PHI_zz = autograd.grad(PHI_x_3,g,torch.ones([x_to_train_f.shape[0], 1]).to(device), retain_graph=True, create_graph=True)[0]\n",
    "        \n",
    "        PHI_xx_1 = PHI_xx[:,[0]]\n",
    "        PHI_xx_2 = PHI_yy[:,[1]]\n",
    "        PHI_xx_3 = PHI_zz[:,[2]]\n",
    "        \n",
    "        deltaPHI = PHI_xx_1 + PHI_xx_2 + PHI_xx_3\n",
    "        \n",
    "        F = v_xx_1 + v_xx_2 + v_xx_3 + f + deltap0 * PHI + 2 * (p_r * x_1_f/r * PHI_x_1 + p_r* x_2_f/r * PHI_x_2) + 2*p_theta*(-x_2_f* PHI_x_1 + x_1_f * PHI_x_2)/r**2 + p * deltaPHI\n",
    "        \n",
    "        loss_f = self.loss_function(F, f_hat)\n",
    "        \n",
    "        return loss_f\n",
    "    \n",
    "    def loss(self,x,y,x_to_train_f,sigma):\n",
    "\n",
    "        loss_v = self.loss_BC(x,y)\n",
    "        loss_f = self.loss_PDE(x_to_train_f)\n",
    "\n",
    "        loss = sigma * loss_v + loss_f\n",
    "\n",
    "        return loss\n",
    "     \n",
    "    'callable for optimizer'                                       \n",
    "    def closure(self):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss_val = self.loss(X_v_train, v_train, X_f_train, sigma)\n",
    "        \n",
    "        #error_vec, _ = PINN.test()\n",
    "        \n",
    "        #print(loss_val,error_vec)\n",
    "        \n",
    "        global ite, iteration_vec, error_vec, fun_vec\n",
    "        ite = ite + 1\n",
    "        \n",
    "        if (ite % 100 == 0):\n",
    "            iteration_vec.append(ite)\n",
    "            fun_vec.append(loss_val.item())\n",
    "            error, _, error_PHI = self.test()\n",
    "            error_vec.append(error.item())\n",
    "            error_PHI_vec.append(error_PHI.item())\n",
    "        \n",
    "        loss_val.backward()\n",
    "\n",
    "        return loss_val        \n",
    "    \n",
    "    def test(self):\n",
    "                \n",
    "        v_pred = self.forward(X_v_test_tensor)\n",
    "        \n",
    "        PHI_pred = self.forward0(X_v_test_tensor)\n",
    "        \n",
    "        error_0 = torch.linalg.norm((v-v_pred),2)/torch.linalg.norm(v,2)        # Relative L2 Norm of the error (Vector)\n",
    "        \n",
    "        PHI_tor = torch.where(X_v_test_tensor[:,[0]]**2 + X_v_test_tensor[:,[1]]**2>R**2, 0, PHI_torch)\n",
    "        PHI_pred = torch.where(X_v_test_tensor[:,[0]]**2 + X_v_test_tensor[:,[1]]**2>R**2, 0, PHI_pred)\n",
    "        \n",
    "        error_PHI = torch.linalg.norm((PHI_tor-PHI_pred),2)/torch.linalg.norm(PHI_tor,2)\n",
    "        \n",
    "        u_pred = v_pred.cpu().detach().numpy() + PHI_pred.cpu().detach().numpy() * sd * etad\n",
    "\n",
    "        return error_0, u_pred, error_PHI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea9853d",
   "metadata": {},
   "source": [
    "# Loss Function\n",
    "\n",
    "The loss function consists of two parts:\n",
    "\n",
    "    loss_BC: MSE error of boundary losses\n",
    "    loss_PDE: MSE error of collocation points satisfying the PDE\n",
    "\n",
    "loss = loss_BC + loss_PDE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d71f69f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6580\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=10, bias=True)\n",
      "    (1): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (2): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (3): Linear(in_features=10, out_features=1, bias=True)\n",
      "  )\n",
      "  (linears0): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=10, bias=True)\n",
      "    (1): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (2): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (3): Linear(in_features=10, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "tensor(0.0809, grad_fn=<DivBackward0>)\n",
      "tensor(0.0396, grad_fn=<DivBackward0>)\n",
      "tensor(0.0396, grad_fn=<DivBackward0>)\n",
      "tensor(0.0381, grad_fn=<DivBackward0>)\n",
      "tensor(0.0380, grad_fn=<DivBackward0>)\n",
      "tensor(0.0380, grad_fn=<DivBackward0>)\n",
      "tensor(0.0380, grad_fn=<DivBackward0>)\n",
      "Training time: 2108.08\n",
      "sigma: 4556.250000\n",
      "Test Error: 0.03798\n",
      "iteration: 13158\n",
      "[100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000, 2100, 2200, 2300, 2400, 2500, 2600, 2700, 2800, 2900, 3000, 3100, 3200, 3300, 3400, 3500, 3600, 3700, 3800, 3900, 4000, 4100, 4200, 4300, 4400, 4500, 4600, 4700, 4800, 4900, 5000, 5100, 5200, 5300, 5400, 5500, 5600, 5700, 5800, 5900, 6000, 6100, 6200, 6300, 6400, 6500, 6600, 6700, 6800, 6900, 7000, 7100, 7200, 7300, 7400, 7500, 7600, 7700, 7800, 7900, 8000, 8100, 8200, 8300, 8400, 8500, 8600, 8700, 8800, 8900, 9000, 9100, 9200, 9300, 9400, 9500, 9600, 9700, 9800, 9900, 10000, 10100, 10200, 10300, 10400, 10500, 10600, 10700, 10800, 10900, 11000, 11100, 11200, 11300, 11400, 11500, 11600, 11700, 11800, 11900, 12000, 12100, 12200, 12300, 12400, 12500, 12600, 12700, 12800, 12900, 13000, 13100] [12.212385177612305, 9.695830345153809, 8.86402702331543, 8.587981224060059, 8.41363525390625, 8.09415340423584, 7.479811668395996, 6.318048000335693, 5.158044815063477, 4.685965538024902, 4.349645614624023, 4.083624839782715, 3.776731252670288, 3.527728319168091, 3.222647190093994, 3.026254177093506, 2.8395605087280273, 2.6014304161071777, 2.465665578842163, 2.2496607303619385, 1.9933336973190308, 1.7919626235961914, 1.5907765626907349, 1.456037163734436, 1.3106703758239746, 1.1557140350341797, 1.04269540309906, 0.9575594663619995, 0.88312166929245, 0.8169568181037903, 0.7530819177627563, 0.684816300868988, 0.6353643536567688, 0.5964875221252441, 0.5592257976531982, 0.5293575525283813, 0.5067508816719055, 0.48586177825927734, 0.4681285619735718, 0.456352174282074, 0.44219163060188293, 0.4270092844963074, 0.41121557354927063, 0.39085128903388977, 0.3691433072090149, 0.3497046232223511, 0.33592939376831055, 0.3241828382015228, 0.3145408630371094, 0.3033483624458313, 0.29562968015670776, 0.28876346349716187, 0.28240513801574707, 0.27716970443725586, 0.27009880542755127, 0.2653099596500397, 0.2593134939670563, 0.25438904762268066, 0.24951717257499695, 0.24407511949539185, 0.2383301705121994, 0.23313845694065094, 0.24029316008090973, 0.23676332831382751, 0.2325112372636795, 0.2289901226758957, 0.22568808495998383, 0.22151640057563782, 0.2178514003753662, 0.21440185606479645, 0.2113276720046997, 0.20828667283058167, 0.20469200611114502, 0.2018686681985855, 0.19954480230808258, 0.1969933956861496, 0.19421634078025818, 0.19172155857086182, 0.18983040750026703, 0.18733695149421692, 0.18396198749542236, 0.1810135543346405, 0.17886456847190857, 0.176278218626976, 0.17434613406658173, 0.1720457524061203, 0.1704920530319214, 0.16892991960048676, 0.16746823489665985, 0.1659044623374939, 0.16416174173355103, 0.1625293493270874, 0.1611853539943695, 0.15988294780254364, 0.15836703777313232, 0.1565798670053482, 0.1549730747938156, 0.1530807912349701, 0.15181538462638855, 0.1506616473197937, 0.1495417356491089, 0.1482880860567093, 0.14666707813739777, 0.1453646421432495, 0.14404095709323883, 0.14300185441970825, 0.1419941931962967, 0.1407848745584488, 0.1396222561597824, 0.1383672058582306, 0.13717946410179138, 0.135818749666214, 0.1347324550151825, 0.1336214244365692, 0.13294030725955963, 0.13216686248779297, 0.1314096748828888, 0.1305626779794693, 0.12976662814617157, 0.12849144637584686, 0.12714403867721558, 0.12592701613903046, 0.12486372888088226, 0.1237347424030304, 0.12277108430862427, 0.13307498395442963, 0.13218948245048523, 0.13183990120887756, 0.13132542371749878, 0.13073542714118958, 0.12985104322433472] [0.9579684734344482, 0.9291504621505737, 0.8378375172615051, 0.7689821720123291, 0.7475248575210571, 0.6965978741645813, 0.6307322978973389, 0.6408088207244873, 0.5140964984893799, 0.4929002523422241, 0.504831075668335, 0.5032030344009399, 0.4849882125854492, 0.4772563576698303, 0.47069960832595825, 0.4136693477630615, 0.3893609642982483, 0.3613791763782501, 0.3397241234779358, 0.34238436818122864, 0.30577921867370605, 0.3027384579181671, 0.27195265889167786, 0.27262091636657715, 0.2521136403083801, 0.212006613612175, 0.18838371336460114, 0.17502278089523315, 0.1564980000257492, 0.15246251225471497, 0.14883413910865784, 0.13718217611312866, 0.1392543762922287, 0.12544430792331696, 0.11912187933921814, 0.10933063924312592, 0.10680504888296127, 0.09988145530223846, 0.09629324823617935, 0.0966198667883873, 0.09425708651542664, 0.09794890135526657, 0.09942108392715454, 0.09566891193389893, 0.10247138887643814, 0.09650097787380219, 0.09750133007764816, 0.09592065960168839, 0.09212945401668549, 0.09517544507980347, 0.09123558551073074, 0.09159758687019348, 0.09014057368040085, 0.08594297617673874, 0.08556720614433289, 0.08577240258455276, 0.08222059905529022, 0.08359166234731674, 0.0824713259935379, 0.08378192782402039, 0.08176415413618088, 0.07962147891521454, 0.07897456735372543, 0.07476663589477539, 0.07342827320098877, 0.07199883460998535, 0.07024189084768295, 0.06755032390356064, 0.06842321902513504, 0.06762778759002686, 0.06802085041999817, 0.06619953364133835, 0.06310024857521057, 0.061628274619579315, 0.06333397328853607, 0.06359783560037613, 0.06333725899457932, 0.060644980520009995, 0.058705370873212814, 0.058405801653862, 0.05684427544474602, 0.05404939875006676, 0.0515986867249012, 0.050307903438806534, 0.05140857398509979, 0.051840025931596756, 0.050906483083963394, 0.050262078642845154, 0.050213973969221115, 0.049928877502679825, 0.04985501244664192, 0.045156799256801605, 0.04452003538608551, 0.04488341137766838, 0.04531719163060188, 0.04474206268787384, 0.043618250638246536, 0.042121682316064835, 0.04257636517286301, 0.04295403137803078, 0.04206357151269913, 0.04261879622936249, 0.0425749272108078, 0.042648494243621826, 0.04182325303554535, 0.04013693332672119, 0.03964700177311897, 0.039878182113170624, 0.03950442001223564, 0.039225660264492035, 0.038359396159648895, 0.03855790197849274, 0.038579635322093964, 0.040335915982723236, 0.0403495617210865, 0.04060491919517517, 0.03963176906108856, 0.038603298366069794, 0.03906795009970665, 0.04033740237355232, 0.040267463773489, 0.04063906893134117, 0.038476407527923584, 0.037853654474020004, 0.039560284465551376, 0.03877011686563492, 0.038118042051792145, 0.037931278347969055, 0.03796041011810303, 0.038359712809324265, 0.03826506435871124] [0.5003613233566284, 0.45164602994918823, 0.47213491797447205, 0.4450969099998474, 0.4264460802078247, 0.42683568596839905, 0.4215923249721527, 0.3846072852611542, 0.3204728960990906, 0.2840738594532013, 0.2475089430809021, 0.23328238725662231, 0.21292348206043243, 0.20796354115009308, 0.17991894483566284, 0.1726587563753128, 0.17605215311050415, 0.16714537143707275, 0.16698938608169556, 0.15188534557819366, 0.15775197744369507, 0.15238991379737854, 0.14731693267822266, 0.14912672340869904, 0.14077714085578918, 0.13128650188446045, 0.12651513516902924, 0.13079683482646942, 0.13108797371387482, 0.1363600194454193, 0.14141212403774261, 0.14286909997463226, 0.1353798806667328, 0.14048461616039276, 0.13191542029380798, 0.12695430219173431, 0.1247808188199997, 0.11746044456958771, 0.11853200942277908, 0.11307346075773239, 0.11662804335355759, 0.11697158217430115, 0.11582900583744049, 0.11300612986087799, 0.10634738951921463, 0.10458725690841675, 0.10086342692375183, 0.09978561103343964, 0.09674359858036041, 0.09513262659311295, 0.0965903028845787, 0.09550268948078156, 0.09140556305646896, 0.0916886031627655, 0.08996744453907013, 0.08903796225786209, 0.08791924268007278, 0.08868183195590973, 0.087998166680336, 0.08826828747987747, 0.08786914497613907, 0.08723689615726471, 0.08622670918703079, 0.08592065423727036, 0.0857028141617775, 0.08497388660907745, 0.0842605009675026, 0.08340417593717575, 0.08337009698152542, 0.08187846094369888, 0.08141341060400009, 0.08280729502439499, 0.08229797333478928, 0.08115162700414658, 0.08163115382194519, 0.08079177141189575, 0.08031678944826126, 0.08015133440494537, 0.0802292451262474, 0.08009012043476105, 0.08062493056058884, 0.07981757074594498, 0.07895395904779434, 0.07801362872123718, 0.07698971778154373, 0.07635244727134705, 0.0759698823094368, 0.07507377862930298, 0.07488490641117096, 0.07455899566411972, 0.07449746876955032, 0.07434508949518204, 0.07413246482610703, 0.07438250631093979, 0.07446996867656708, 0.07473120838403702, 0.07465556263923645, 0.07561146467924118, 0.07579973340034485, 0.07567387819290161, 0.07598675042390823, 0.0766102597117424, 0.07649369537830353, 0.07682595402002335, 0.0766984224319458, 0.07663389295339584, 0.0767413005232811, 0.07651843130588531, 0.07605349272489548, 0.07569894194602966, 0.07503800094127655, 0.07408458739519119, 0.07373328506946564, 0.07382576912641525, 0.07441607862710953, 0.07459892332553864, 0.07469407469034195, 0.07490842044353485, 0.07506009191274643, 0.07518357038497925, 0.07525251805782318, 0.07629715651273727, 0.07601257413625717, 0.07543304562568665, 0.07458366453647614, 0.07447770982980728, 0.07455179840326309, 0.07463540136814117, 0.07478085905313492, 0.07481362670660019, 0.07454393059015274]\n"
     ]
    }
   ],
   "source": [
    "N_v = 800\n",
    "N_f = 10000\n",
    "\n",
    "X_f_train_np_array, X_v_train_np_array, v_train_np_array = trainingdata(N_v,N_f)\n",
    "\n",
    "'Convert to tensor and send to GPU'\n",
    "X_f_train = torch.from_numpy(X_f_train_np_array).float().to(device)\n",
    "X_v_train = torch.from_numpy(X_v_train_np_array).float().to(device)\n",
    "#v_train = torch.zeros(X_v_train.shape[0],1).to(device)\n",
    "v_train = torch.from_numpy(v_train_np_array).float().to(device)\n",
    "X_v_test_tensor = torch.from_numpy(X_v_test).float().to(device)\n",
    "v = torch.from_numpy(v_true).float().to(device)\n",
    "u = torch.from_numpy(u_true).float().to(device)\n",
    "f_hat = torch.zeros(X_f_train.shape[0],1).to(device)\n",
    "PHI_torch = torch.from_numpy(PHI).float().to(device)\n",
    "\n",
    "layers = np.array([3,10,10,10,1])\n",
    "layers0 = np.array([3,10,10,10,1])\n",
    "\n",
    "PINN = Sequentialmodel(layers,layers0)\n",
    "       \n",
    "PINN.to(device)\n",
    "\n",
    "'Neural Network Summary'\n",
    "\n",
    "print(PINN)\n",
    "\n",
    "iteration_vec = []\n",
    "fun_vec = []\n",
    "error_vec = []\n",
    "error_PHI_vec = []\n",
    "\n",
    "params = list(PINN.parameters())\n",
    "\n",
    "sigma = 400\n",
    "\n",
    "start_time = time.time()\n",
    "error_0 = 1\n",
    "\n",
    "ite = 0\n",
    "\n",
    "while sigma<5000 and error_0>0.01:\n",
    "    optimizer = torch.optim.LBFGS(PINN.parameters(), lr=0.1,\n",
    "                              max_iter = 5000, \n",
    "                              max_eval = None, \n",
    "                              tolerance_grad = 1e-06, \n",
    "                              tolerance_change = 1e-09, \n",
    "                              history_size = 100,\n",
    "                              line_search_fn = 'strong_wolfe')\n",
    "\n",
    "    optimizer.zero_grad()     # zeroes the gradient buffers of all parameters\n",
    "    optimizer.step(PINN.closure)\n",
    "    sigma = 1.5 * sigma\n",
    "    error_0, _, _ = PINN.test()\n",
    "    print(error_0)\n",
    "\n",
    "elapsed = time.time() - start_time                \n",
    "print('Training time: %.2f' % (elapsed))\n",
    "\n",
    "''' Model Accuracy ''' \n",
    "error_0, u_pred,_ = PINN.test()\n",
    "\n",
    "print('sigma: %f' %(sigma/1.5))\n",
    "print('Test Error: %.5f'  % (error_0))\n",
    "print('iteration: %d' %(ite))\n",
    "\n",
    "print(iteration_vec,fun_vec,error_vec,error_PHI_vec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
